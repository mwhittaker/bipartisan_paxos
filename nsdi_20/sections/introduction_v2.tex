\section{Introduction}
State machine replication protocols like MultiPaxos~\cite{lamport1998part,
lamport2001paxos} and Raft~\cite{ongaro2014search} allow a state machine to be
executed in unison across a number of machines, despite the possibility of
faults. Today, state machine replication is pervasive. Nearly every strongly
consistent distributed system is implemented with some form of state machine
replication~\cite{corbett2013spanner, thomson2012calvin, burrows2006chubby,
baker2011megastore, cockroach2019website, cosmos2019website, tidb2019website,
yugabyte2019website}.

MultiPaxos is one of the oldest and one of the most widely used state machine
replication protocols. However, despite its popularity, MultiPaxos does not have
optimal throughput or optimal latency. In response, a number of state machine
replication protocols have been proposed to address MultiPaxos' suboptimal
performance~\cite{%
  arun2017speeding,
  biely2012s,
  howard2016flexible,
  lamport2005generalized,
  lamport2006fast,
  li2016just,
  mao2008mencius,
  moraru2013there,
  nawab2018dpaxos,
  park2019exploiting,
  ports2015designing
}.
These protocols use sophisticated techniques that either increase MultiPaxos'
throughput, decrease its latency, or both

These sophisticated replication protocols have two shortcomings: they do not
scale, and they are very complicated. In this paper, we address both these
shortcomings with a single solution: \textbf{modularity}. We present Bipartisan
Paxos (BPaxos), a state machine replication protocol that is composed of a
number of independent modules. Modularity allows us to achieve state of the art
throughput via a straightforward form of scaling, and modularity makes BPaxos
significantly easier to understand compared to similar protocols.

\paragraph{Scaling}
Simple state machine replication protocols like MultiPaxos and Raft do not
scale. Conventional wisdom encourages us to use as few nodes as possible when
deploying these protocols: ``using more than $2f+1$ replicas for $f$ failures
is possible but illogical because it requires a larger quorum size with no
additional benefit''~\cite{zhang2018building}. Some protocols use multiple
leaders to avoid being bottlenecked by a single leader~\cite{mao2008mencius,
moraru2013there, arun2017speeding}. This is a good first step towards
scalability, but these protocols all prescribe a fixed number of leaders
(typically $2f+1$ leaders to tolerate $f$ faults).

BPaxos, on the other hand, employs a straightforward form of scaling to achieve
high throughput. A BPaxos deployment consists of a set of leaders, dependency
service nodes, proposers, acceptors, and replicas. We will see later that
dependency service nodes, acceptors, and replicas do not scale. This is why
conventional wisdom dictates using as few of these nodes as possible.  However,
we show that leaders and proposers operate independently from one another and
are thus ``embarrassingly scalable''. Moreover, when we perform a bottleneck
analysis on BPaxos, we find that these scalable leaders and proposers are the
throughput bottleneck. By increasing the number of leaders and proposers, we
increase the protocol's throughput. BPaxos is able to achieve roughly double
the peak throughput of EPaxos, a state of the art replication protocol.

This straightforward form of scaling has been largely overlooked because most
existing replication protocols tightly couple their components together. For
example, an EPaxos replica plays the role of a leader, a dependency service
node, an acceptor, \emph{and} a replica~\cite{arun2017speeding}. This tight
coupling has a number of advantages---e.g., messages sent between co-located
nodes do not have to traverse the network, redundant metadata can be coalesced,
fast paths can be taken to reduce latency, and so on. However, tight coupling
lumps together components that do not scale with components that do. This
prevents independently scaling bottleneck components. BPaxos' modularity is the
key enabling feature that allows us to perform independent scaling.

\paragraph{Simplicity}
MultiPaxos is notoriously difficult to understand, and sophisticated protocols
that improve it are significantly more complex. BPaxos' modular design, on the
other hand, makes the protocol easy to understand. Each module can be
understood and proven correct in isolation, allowing newcomers to understand
the protocol piece by piece, something that is difficult to do with existing
protocols in which components are tightly coupled.

Moreover, some of the modules implement well-known abstractions for which
well-established protocols already exist. In these cases, BPaxos can leverage
existing protocols instead of reinventing the wheel. For example, BPaxos
depends on a module that implements consensus. Rather than implementing a
consensus protocol from scratch and having to prove it correct, BPaxos instead
uses Paxos off the shelf and inherits its safety properties. Many other
protocols~\cite{moraru2013there, arun2017speeding, nawab2018dpaxos} instead
implement consensus in a way that is specialized to the protocol. These
specialized consensus protocols are difficult to understand and difficult to
prove correct. As an anecdote, we discovered a minor bug in EPaxos'
implementation of consensus, which we confirmed with the authors, a bug that
went undiscovered for six years.

% It is difficult to precisely measure the ``complexity'' of a protocol, how hard
% it is for someone to understand it. However, in \secref{Discussion}, we present
% a number of quantitative and qualitative metrics that demonstrate BPaxos'
% simplicity.

\paragraph{Summary}
In summary, we present the following contributions:
\begin{itemize}
  \item
    We introduce BPaxos, a modular, multileader, generalized state machine
    replication protocol.
  \item
    We describe how modularity enables a straightforward form of protocol
    scaling. We apply the technique to BPaxos and achieve double the peak
    throughput of a state of the art replication protocol.
  \item
    We demonstrate how BPaxos' modularity makes the protocol significantly
    easier to understand compared to similar protocols.
\end{itemize}
